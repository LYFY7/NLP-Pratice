{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, cols):\n",
    "    data = pd.read_csv(path, sep='\\t', usecols = cols)\n",
    "    text = []\n",
    "    label = []\n",
    "    \n",
    "    for i in data.values:\n",
    "        text.append(i[0])\n",
    "        label.append(i[1])\n",
    "        \n",
    "    return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, label = read_data('./data/train.tsv', ['Phrase', 'Sentiment'])\n",
    "text = [i.split(' ') for i in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data\n",
    "from torchtext import vocab\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential = True, fix_length = 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = '.vector_cache'\n",
    "vectors = vocab.Vectors(name='./glove/glove.6B.300d.txt', cache = cache)\n",
    "TEXT.build_vocab(text, vectors = vectors, unk_init = torch.nn.init.xavier_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_text = TEXT.process(text)\n",
    "process_text = process_text.permute(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   45,   316,     5, 16579,  6249,     2,  6882,    12,    72,    11,\n",
       "           56,    16,     2,  4669,    11,   174,    56,    16,     2, 12561,\n",
       "            3,    73,     5,    86,   644, 11258,    22,   738,     5,    86,\n",
       "         2011,     7,    63,     5,     4,    47])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = process_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132651, 36) (132651,)\n",
      "(23409, 36) (23409,)\n"
     ]
    }
   ],
   "source": [
    "random_order = list(range(len(input_ids)))\n",
    "np.random.seed(2020)   # 固定种子\n",
    "np.random.shuffle(random_order)\n",
    "\n",
    "# 4:1 划分训练集和测试集\n",
    "input_ids_train = np.array([input_ids[i].numpy() for i in random_order[:int(len(input_ids)*0.85)]])\n",
    "y_train = np.array([label[i] for i in random_order[:int(len(input_ids) * 0.85)]])\n",
    "\n",
    "print(input_ids_train.shape, y_train.shape)\n",
    "\n",
    "input_ids_test = np.array([input_ids[i].numpy() for i in random_order[int(len(input_ids)*0.85):]])\n",
    "y_test = np.array([label[i] for i in random_order[int(len(input_ids)*0.85):]])\n",
    "\n",
    "print(input_ids_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import *\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_data = TensorDataset(torch.LongTensor(input_ids_train), \n",
    "                           torch.LongTensor(y_train))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE)\n",
    "\n",
    "test_data = TensorDataset(torch.LongTensor(input_ids_test), \n",
    "                          torch.LongTensor(y_test))\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(len(TEXT.vocab), 300)\n",
    "        # 权重在词汇表vocab的vectors属性中\n",
    "        self.weight_matrix = TEXT.vocab.vectors\n",
    "        # 指定嵌入矩阵的初始权重\n",
    "        self.embedding.weight.data.copy_(self.weight_matrix)\n",
    "        self.embedding.weight.requires_grad = True     \n",
    "        \n",
    "        self.lstm = nn.LSTM(300, 128, bidirectional = True, num_layers = 3, batch_first = True, dropout = 0.5)\n",
    "        self.fc = nn.Linear(256, 128)\n",
    "        self.fc1 = nn.Linear(128, 5)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.embedding(x)\n",
    "        out, hidden = self.lstm(out)\n",
    "        out = torch.cat((hidden[0][-2], hidden[0][-1]), dim = -1) # 拼接前向与后向向量\n",
    "        out = self.act(self.fc(out))\n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "lstm_model = LSTMModel().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 3\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1轮, average loss: 0.9209; 准确率为: 0.66%\n",
      "第2轮, average loss: 0.7412; 准确率为: 0.67%\n",
      "第3轮, average loss: 0.6641; 准确率为: 0.67%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    lstm_model.train()\n",
    "    sta_loss = []\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        text, label = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "        pred_label = lstm_model(text)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(pred_label, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        sta_loss.append(loss.item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lstm_model.eval()\n",
    "        pred_test = []\n",
    "        true_test = []\n",
    "            \n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            text, label = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "            pred_label = lstm_model(text)\n",
    "            pred_test.extend(pred_label.argmax(dim=1).cpu().numpy())\n",
    "            true_test.extend(label.cpu().numpy())\n",
    "        \n",
    "        print('第{}轮, average loss: {:.4}; 准确率为: {:.2}%'.format(epoch+1, sum(sta_loss)/len(sta_loss)*100, accuracy_score(pred_test, true_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/test.tsv', sep='\\t', usecols = ['Phrase'])\n",
    "submit_text = []\n",
    "for i in data.values:\n",
    "    submit_text.append(i[0])\n",
    "    \n",
    "submit_text = [i.split(' ') for i in submit_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_submit_text = TEXT.process(submit_text)\n",
    "process_submit_text = process_submit_text.permute(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_data = TensorDataset(torch.LongTensor(np.array(process_submit_text)))\n",
    "\n",
    "submit_loader = DataLoader(submit_data, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    lstm_model.eval()\n",
    "    pred_submit = []\n",
    "        \n",
    "    for batch_idx, data in enumerate(submit_loader):\n",
    "        x = data[0].to(DEVICE)\n",
    "        pred_label = lstm_model(x)\n",
    "        pred_submit.extend(pred_label.argmax(dim=1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in range(156061, 222353):\n",
    "    res.append([i, pred_submit[i-156061]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(res, columns = ['PhraseId', 'Sentiment'])\n",
    "submit.to_csv('./submit/lstm_submit.csv', index = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
